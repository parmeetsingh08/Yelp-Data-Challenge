{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import load_sparse_csr\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED_VAL = 200\n",
    "n_words=10000\n",
    "data_subset = \"_10Percent\"\n",
    "VALIDATION_DATA_PERCENTAGE = 0.1\n",
    "WORK_DIR = os.getcwd()\n",
    "YELP_DATA_CSV_DIR = os.path.join(WORK_DIR, \"data\", \"csv\")\n",
    "YELP_DATA_WORD_2_VEC_MODEL_DIR = os.path.join(WORK_DIR, \"data\", \"word2vec_model\")\n",
    "YELP_DATA_SPARSE_MATRIX_DIR = os.path.join(WORK_DIR, \"data\", \"sparse_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrushikesh/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "read_filename = os.path.join(YELP_DATA_CSV_DIR, 'business_review_user'+ data_subset+ '.csv')\n",
    "df_data = pd.read_csv(read_filename, engine='c', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myLSTM(trainDataVecs, y,SEED_VAL=SEED_VAL):\n",
    "    '''\n",
    "    Function to train LSTM and print the accuracy for train and test.\n",
    "    \n",
    "    Divides the data in train 90% and test 10%. \n",
    "    \n",
    "    Inputs\n",
    "    trainDataVecs - Numpy darray matrix\n",
    "    y - Numpy darray for vector\n",
    "    SEED_VAL = seed for randomly shuffling the data\n",
    "    \n",
    "    Output\n",
    "    prints the accuracy of trained model on training and testing data\n",
    "    '''\n",
    "    # Divide the data in test and train\n",
    "    np.random.seed = SEED_VAL\n",
    "    n_samples = len(trainDataVecs)\n",
    "    sidx = np.random.permutation(n_samples)\n",
    "    data_set_x = trainDataVecs.tolist()\n",
    "    b = y\n",
    "    \n",
    "    # b[(b == 1) | (b == 2) | (b == 3)] = 0\n",
    "    # b[(b == 4) | (b == 5)] = 1\n",
    "    data_set_y = b.tolist()\n",
    "\n",
    "    n_train = int(np.round(n_samples * (1. - VALIDATION_DATA_PERCENTAGE)))\n",
    "    valid_set_x = [data_set_x[s] for s in sidx[n_train:]]\n",
    "    valid_set_y = [data_set_y[s] for s in sidx[n_train:]]\n",
    "    train_set_x = [data_set_x[s] for s in sidx[:n_train]]\n",
    "    train_set_y = [data_set_y[s] for s in sidx[:n_train]]\n",
    "\n",
    "    # def remove_unk(x):\n",
    "    #     return [[1 if w >= n_words else w for w in sen] for sen in x]\n",
    "\n",
    "    # train_set_x = remove_unk(train_set_x)\n",
    "    # valid_set_x = remove_unk(valid_set_x)\n",
    "\n",
    "    train = (train_set_x, train_set_y)\n",
    "    valid = (valid_set_x, valid_set_y)\n",
    "\n",
    "    max_features = 100\n",
    "    maxlen = trainDataVecs.shape[1]  # cut texts after this number of words (among top max_features most common words)\n",
    "    batch_size = 32\n",
    "\n",
    "    X_train, y_train=train[0], train[1]\n",
    "    X_test, y_test= valid[0], valid[1]\n",
    "\n",
    "    print(\"Pad sequences (samples x time)\")\n",
    "    # http://keras.io/preprocessing/sequence/\n",
    "    X_train = sequence.pad_sequences(X_train, maxlen=maxlen, dtype='float32')\n",
    "    X_test = sequence.pad_sequences(X_test, maxlen=maxlen, dtype='float32')\n",
    "\n",
    "    y_train = np.array(y_train, dtype='int32')\n",
    "    y_test = np.array(y_test, dtype='int32')\n",
    "\n",
    "    print('Build model...')\n",
    "    # http://keras.io/objectives/\n",
    "    # http://keras.io/optimizers/\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "    model.add(LSTM(128))  # try using a GRU instead, for fun\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    # model.compile(loss='binary_crossentropy',\n",
    "    #               optimizer='adam',\n",
    "    #               class_mode=\"binary\")\n",
    "\n",
    "    # 'mean_squared_error', binary_crossentropy\n",
    "\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "    print(\"Train...\")\n",
    "    %time model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=3, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "    score1, accuracy1 = model.evaluate(X_train, y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                show_accuracy=True)\n",
    "    \n",
    "    print('Train score:', score1)\n",
    "    print ('Train Accuracy: ', accuracy1)\n",
    "    \n",
    "    score2, accuracy2 = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size,\n",
    "                            show_accuracy=True)\n",
    "    \n",
    "    print('Test score:', score2)\n",
    "    print ('Test Accuracy: ', accuracy2)\n",
    "    \n",
    "    \n",
    "y = np.array(df_data.review_stars.copy(), dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spare_matrix_file = os.path.join(YELP_DATA_SPARSE_MATRIX_DIR, \"bagWords\"+ data_subset)\n",
    "bag_of_words_sparse_matrix = load_sparse_csr(spare_matrix_file + \".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 197356 samples, validate on 21929 samples\n",
      "Epoch 1/3\n",
      "   320/197356 [..............................] - ETA: 17156s - loss: 11.1349 - acc: 0.1094"
     ]
    }
   ],
   "source": [
    "matrix_bag_of_words = bag_of_words_sparse_matrix.toarray()\n",
    "myLSTM(matrix_bag_of_words, y, SEED_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bag of words + Hand craft features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\_Active_Projects\\\\yelp\\\\yelp\\\\data\\\\sparse_matrix\\\\bagWords_feat_add_10Percent.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9182947eac16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mspare_matrix_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYELP_DATA_SPARSE_MATRIX_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bagWords_feat_add\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeature_matrix_bag_of_words_and_hand_craft_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_sparse_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspare_matrix_file\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".npz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\_Active_Projects\\yelp\\yelp\\utils.pyc\u001b[0m in \u001b[0;36mload_sparse_csr\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_sparse_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     return csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n\u001b[0;32m     87\u001b[0m                          shape = loader['shape'])\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\lib\\npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\_Active_Projects\\\\yelp\\\\yelp\\\\data\\\\sparse_matrix\\\\bagWords_feat_add_10Percent.npz'"
     ]
    }
   ],
   "source": [
    "spare_matrix_file = os.path.join(YELP_DATA_SPARSE_MATRIX_DIR, \"bagWords_feat_add\" + data_subset)\n",
    "feature_matrix_bag_of_words_and_hand_craft_features = load_sparse_csr(spare_matrix_file + \".npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 2002 samples, validate on 223 samples\n",
      "Epoch 1/3\n",
      " 128/2002 [>.............................] - ETA: 3715s - loss: 12.4253 - acc: 0.0938"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-413e2f14cf0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmyLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix_bag_of_words_and_hand_craft_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEED_VAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-5e07bb0d9c40>\u001b[0m in \u001b[0;36mmyLSTM\u001b[1;34m(trainDataVecs, y, SEED_VAL)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=3,\n\u001b[1;32m---> 65\u001b[1;33m               validation_data=(X_test, y_test))\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hrushikesh/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/hrushikesh/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1028\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hrushikesh/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hrushikesh/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hrushikesh/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myLSTM(feature_matrix_bag_of_words_and_hand_craft_features.toarray(), y, SEED_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_feature_matrix_file = os.path.join(YELP_DATA_WORD_2_VEC_MODEL_DIR, \"word2vec_feature_matrix\" + data_subset+ \".csv\")\n",
    "feature_matrix_word2vec = np.genfromtxt(word2vec_feature_matrix_file, delimiter=',')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 2002 samples, validate on 223 samples\n",
      "Epoch 1/3\n",
      "2002/2002 [==============================] - 13s - loss: 9.7223 - acc: 0.1194 - val_loss: 9.8704 - val_acc: 0.1121\n",
      "Epoch 2/3\n",
      "2002/2002 [==============================] - 13s - loss: 9.5126 - acc: 0.1209 - val_loss: 9.8702 - val_acc: 0.1121\n",
      "Epoch 3/3\n",
      "2002/2002 [==============================] - 15s - loss: 9.5124 - acc: 0.1209 - val_loss: 9.8701 - val_acc: 0.1121\n",
      "2002/2002 [==============================] - 4s     \n",
      "Train score: 9.51211987533\n",
      "Train Accuracy:  0.120879120887\n",
      "223/223 [==============================] - 0s     \n",
      "Test score: 9.87009063002\n",
      "Test Accuracy:  0.112107623051\n"
     ]
    }
   ],
   "source": [
    "myLSTM(feature_matrix_word2vec, y, SEED_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding + Hand craft features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_feature_matrix_file = os.path.join(YELP_DATA_WORD_2_VEC_MODEL_DIR, \"word2vec_add_feature_matrix\" + data_subset+ \".csv\")\n",
    "feature_matrix_word2vec_and_hand_craft_features = np.genfromtxt(word2vec_feature_matrix_file, delimiter=',')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 2002 samples, validate on 223 samples\n",
      "Epoch 1/3\n",
      "2002/2002 [==============================] - 14s - loss: 9.7028 - acc: 0.1174 - val_loss: 10.0139 - val_acc: 0.1345\n",
      "Epoch 2/3\n",
      "2002/2002 [==============================] - 14s - loss: 9.4967 - acc: 0.1184 - val_loss: 10.0137 - val_acc: 0.1345\n",
      "Epoch 3/3\n",
      "2002/2002 [==============================] - 14s - loss: 9.4963 - acc: 0.1184 - val_loss: 10.0136 - val_acc: 0.1345\n",
      "2002/2002 [==============================] - 5s     \n",
      "Train score: 9.49611577407\n",
      "Train Accuracy:  0.118381618426\n",
      "223/223 [==============================] - 0s     \n",
      "Test score: 10.0135671675\n",
      "Test Accuracy:  0.134529147314\n"
     ]
    }
   ],
   "source": [
    "myLSTM(feature_matrix_word2vec_and_hand_craft_features, y, SEED_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hand craft features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix_hand_craft_features = feature_matrix_word2vec_and_hand_craft_features[:,100:104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 2002 samples, validate on 223 samples\n",
      "Epoch 1/3\n",
      "2002/2002 [==============================] - 1s - loss: 10.1891 - acc: 0.1194 - val_loss: 10.4440 - val_acc: 0.1121\n",
      "Epoch 2/3\n",
      "2002/2002 [==============================] - 1s - loss: 9.4481 - acc: 0.1209 - val_loss: 10.4440 - val_acc: 0.1121\n",
      "Epoch 3/3\n",
      "2002/2002 [==============================] - 1s - loss: 9.4481 - acc: 0.1209 - val_loss: 10.4440 - val_acc: 0.1121\n",
      "2002/2002 [==============================] - 0s     \n",
      "Train score: 9.44807190947\n",
      "Train Accuracy:  0.120879120883\n",
      "223/223 [==============================] - 0s     \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b91209a662fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmyLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix_hand_craft_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEED_VAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-5e07bb0d9c40>\u001b[0m in \u001b[0;36mmyLSTM\u001b[1;34m(trainDataVecs, y, SEED_VAL)\u001b[0m\n\u001b[0;32m     77\u001b[0m                             show_accuracy=True)\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Test Accuracy: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hrushikesh/anaconda/lib/python2.7/site-packages/ipykernel/iostream.pyc\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "myLSTM(feature_matrix_hand_craft_features, y, SEED_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
